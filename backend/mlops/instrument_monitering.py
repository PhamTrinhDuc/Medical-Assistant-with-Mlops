import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), ".."))
from opentelemetry import metrics
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.exporter.prometheus import PrometheusMetricReader
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from prometheus_client import make_asgi_app
import time
from functools import wraps
from typing import Callable
from utils import logger

# ============================================================
# OpenTelemetry Setup
# ============================================================

# Táº¡o Prometheus exporter
prometheus_reader = PrometheusMetricReader()

# Táº¡o MeterProvider vá»›i Prometheus exporter
meter_provider = MeterProvider(metric_readers=[prometheus_reader])
metrics.set_meter_provider(meter_provider)

# Táº¡o meter cho app (nhÆ° má»™t namespace)
meter = metrics.get_meter(
    name="chatbot.metrics",
    version="1.0.0"
)

# ============================================================
# Custom Metrics
# ============================================================

# Counter - Äáº¿m requests
chat_requests_total = meter.create_counter(
    name="chat_requests_total",
    description="Total number of chat requests",
    unit="1"
)

# Histogram - Äo latency
chat_request_duration = meter.create_histogram(
    name="chat_request_duration_seconds",
    description="Duration of chat requests in seconds",
    unit="s"
)

# Counter - Äáº¿m tokens
chat_token_total = meter.create_counter(
    name="chat_token_total",
    description="Total number of tokens processed in chat",
    unit="1"
)

# UpDownCounter - Active sessions (cÃ³ thá»ƒ tÄƒng/giáº£m)
active_chat_sessions = meter.create_up_down_counter(
    name="active_chat_sessions",
    description="Number of active chat sessions",
    unit="1"
)

# Counter - Tool calls
agent_tool_calls = meter.create_counter(
    name="agent_tool_calls_total",
    description="Total number of agent tool calls",
    unit="1"
)

def monitor_endpoint(endpoint_name: str):
  """
  Decorator Ä‘á»ƒ theo dÃµi cÃ¡c endpoint cá»¥ thá»ƒ trong á»©ng dá»¥ng.
  
  Sá»­ dá»¥ng OpenTelemetry Ä‘á»ƒ track:
  - Request count (success/error)
  - Request duration (latency)
  - Active sessions
  
  Usage:
      @monitor_endpoint("chat")
      async def chat_endpoint(...):
          ...
  """

  def decorator(func: Callable): 
    @wraps(func)
    async def wrapper(*args, **kwargs): 
      start_time = time.time()
      
      # Attributes (labels) cho metrics
      attributes = {"endpoint": endpoint_name}
      
      # TÄƒng active sessions
      active_chat_sessions.add(1, attributes)

      try: 
        # Execute function
        result = await func(*args, **kwargs)
        
        # Calculate duration
        duration = time.time() - start_time
        
        # Record metrics vá»›i attributes
        chat_request_duration.record(duration, attributes)
        chat_requests_total.add(1, {**attributes, "status": "success"})
        
        return result
        
      except Exception as e:
        # Record error
        chat_requests_total.add(1, {**attributes, "status": "error"})
        raise e
        
      finally: 
        # Giáº£m active sessions
        active_chat_sessions.add(-1, attributes)
        
    return wrapper
  return decorator

def track_tool_usage(result: dict): 
  """Track agent tool calls tá»« result."""
  for step in result.get("intermediate_steps", []): 
    if hasattr(step, "tool"): 
      agent_tool_calls.add(1, {"tool_name": step.tool})

def track_tokens_usage(result: dict, endpoint: str): 
  """Track token usage tá»« LLM response."""
  if "token_usage" in result:
    # Input tokens
    input_tokens = result["token_usage"].get("input", 0)
    if input_tokens > 0:
      chat_token_total.add(
        input_tokens, 
        {"endpoint": endpoint, "type": "input"}
      )
    
    # Output tokens
    output_tokens = result["token_usage"].get("output", 0)
    if output_tokens > 0:
      chat_token_total.add(
        output_tokens,
        {"endpoint": endpoint, "type": "output"}
      )

def setup_metrics(app): 
  """
  Thiáº¿t láº­p OpenTelemetry instrumentation cho FastAPI app.
  
  Features:
  - Auto-instrument táº¥t cáº£ HTTP requests (latency, status codes, etc.)
  - Expose /metrics endpoint cho Prometheus
  - Custom metrics Ä‘Ã£ define á»Ÿ trÃªn
  
  Gá»i hÃ m nÃ y khi khá»Ÿi táº¡o app:
      app = FastAPI()
      setup_metrics(app)
  """
  try:
    logger.info("ğŸš€ Setting up OpenTelemetry metrics instrumentation")
    # Auto-instrument FastAPI vá»›i OpenTelemetry
    # Tá»± Ä‘á»™ng track: request count, duration, status codes
    FastAPIInstrumentor.instrument_app(
      app,
      excluded_urls="/metrics,/health"  # KhÃ´ng track cÃ¡c endpoints nÃ y
    )
    
    # Mount Prometheus metrics endpoint
    # Prometheus sáº½ scrape endpoint nÃ y Ä‘á»ƒ láº¥y metrics
    metrics_app = make_asgi_app()
    app.mount("/metrics", metrics_app)
    
    return app
  except Exception as e:
    logger.error(f"âŒ Error setting up metrics instrumentation: {e}") 